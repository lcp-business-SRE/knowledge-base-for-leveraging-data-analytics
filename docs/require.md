# データ分析基盤の非機能要求とサービス選定について

## 非機能要求

### 性能要求レベル

- 要求内容:
  - バッチ処理・リアルタイム処理の両方に対応できるシステムであること
  - 負荷に応じてスケールすること
  - 大量データの高速処理が可能であること

### セキュリティ要求

- 要求内容:
  - アクセス制御（認証・認可）の実装
    - カラムレベルのアクセス管理が理想
  - データ暗号化（保存時・転送時）
  - ログ管理・監査証跡の確保
  - 個人情報・機密情報の適切な管理
    - マスキング・もしくは情報量を削ぎ落とすなどができること

### ユーザビリティレベル（内部での運用）

- 要求内容:
  - 導入が容易であること
  - 今後の分析ワークフローにおいてリプレースの必要がない、もしくは容易に交換できるもの
  - 設定変更等が容易なこと

### ユーザビリティレベル（事業者）

- 要求内容:
  - 分析結果やダッシュボードが直感的に閲覧できること
  - 必要な指標やレポートにすぐアクセスできること
  - 操作がシンプルで、専門知識がなくても使いやすいこと
  - データの根拠や解釈が分かりやすく提示されること

### コスト

- 要求内容:
  - 導入・構築費用を最適化すること
  - 運用・保守費用を最小化すること
  - アップデートや障害対応が容易であること
  - 学習コストが小さいほうが望ましい

### 環境要求

- 要求内容:
  - 既存システム・サービスとの親和性（API連携、データ連携）

### 拡張性

- 要求内容:
  - 今後の開発において、技術的負債になりにくい
  - 新規機能追加や他システム連携の柔軟性
  - 外部連携が豊富
  - サービス自体が拡張される見込みがある

### 将来性

- 要求内容:
  - 技術トレンドへの追従性（新技術・新サービス対応）
  - クラウドにベンダーロックインされにくい
  - サービスやフォーマットがオープンである
  - バージョンアップや拡張時の影響範囲が限定的

### 汎用性

- 要求内容:
  - 多様なデータソース・分析手法への対応
  - QUICKTRIPの情報を分析する基盤にも転用が可能
  - 社内のデータに対応可能

### 機能性

- 要求内容:
  - 統計学習・機械学習・自然言語処理等の分析機能を将来的にサポート可能
  - 分析ワークフローの構築時に対応可能

### 保守サポート

- 要求内容:
  - 障害発生時の迅速な対応体制
  - サポート窓口・ドキュメントの充実
  - 定期的なメンテナンス・アップデートの実施
  - GDPR対応

## 採用サービス候補

### データ収集部

#### Amazon Data Firehose

- 用途
  - RDS内のデータのレプリケート手段
- 強み
  - RDSのCDC(Change Data Capture)からデータのレプリケートが可能で、リアルタイム処理やデータ連携の要求を満たす。
  - マネージドサービスなのでメンテが楽
  - 学習コストが低い(QUICKRIDEで使用経験あり)

#### Amazon Sagemaker Lakehouse

データ収集だけでなく、さらに広範囲を統括して扱える。ここではDynamoDBのエクスポートに使うことを念頭に記述。

- 用途
  - DynamoDBのデータレプリケート
- 強み
  - マネージドサービスなのでメンテが楽
  - DynamoDBの情報をリアルタイムで連携できるので、分析が素早く行える
  - セキュリティやアクセス制御（IAM連携、暗号化、監査ログ）が充実しており、ガバナンス要件にも対応可能
    - LakeFormationと連携できる。
  - スケーラブルなアーキテクチャで、将来的なデータ量増加や機能拡張にも柔軟に対応できる
  - マルチユーザー・マルチテナント環境でも運用しやすく、運用コストや保守性にも優れる
  - 継続的なサービスアップデートがあり、将来性・拡張性が高い

#### Airbyte

Fivetranとの比較になる。

- 用途
  - 外部データソースからデータを取得し、Icebergテーブルへ連携する
- 強み
  - セルフホスト型のオープンソースとして導入可能
  - クラウドサービスもあり、月額10ドルから利用可能
  - コネクタの種類が豊富で、GUIによる設定が可能
  - IaC（Infrastructure as Code）に対応（Terraform対応）
  - セルフホストの場合はIcebergへの直接連携が可能
- 懸念点
  - セルフホストの場合、インフラ管理・保守コストが発生
  - クラウド版はIcebergへの直接連携が未対応（今後対応予定）
  - クラウド版は未使用でも最低10ドル/月のコストが発生

#### Fivetran

Airbyteとの比較になる。

- 用途
  - 外部データソースからデータを取得し、Icebergテーブルへ連携する
- 強み
  - 無料枠でGoogle Analytics程度のデータ処理が可能
  - 個人情報のハッシュ化や、同期対象外の選択が可能
  - コネクタが豊富
  - マネージドサービスのため運用負荷が低い
- 懸念点
  - IaCとの連携が弱く、コンソール操作が中心
  - 大規模運用時は従量課金がコスト増につながる可能性
  - 無料枠で使用時に、2回月間処理上限を超える処理を行うとアカウントが凍結される
    - フリープランからの格上げで解放される
  
#### Amazon Glue

- 用途
  - 外部ソースのデータのETL処理
  - ストレージに保存したデータのカタログ化
- 強み
  - マネージドサービスであり、インフラ管理の負担が少ない
  - AWSの他サービスとの統合が容易
  - 使用経験が少しある
  - ETL処理のためのApache Sparkを使用しており、スケーラブルなデータ処理が可能
  - ドキュメントが豊富
- 懸念点
  - ETL処理を行う場合はデータソースそれぞれに対してETLジョブを作成する必要があり、運用負荷が高くなる
    - 特に、データソースが多い場合はETLジョブの数が増え、管理が煩雑になる
  - ETL処理のためにApache Sparkの知識があったほうが良い
  - Step Functionsなどにも手を出すことになる可能性が高い
- 備考
  - S3上でIcebergテーブルを管理する場合は、Glue Data Catalogと連携することになると思われる

### データレイク関連技術

#### AWS S3

- 用途: ストレージ
- 強み
  - 大容量データの保存・取得が高速かつ安価
  - 高い耐障害性・可用性、スケーラビリティを持ち、高速処理の要求にも対応

#### Apache Iceberg

- 用途: データ管理のためのオープンテーブルフォーマット
- 強み
  - 大規模データのテーブル管理やスナップショット機能に優れる
  - データレイクのパフォーマンスと運用性を向上できるため、高速処理や運用性の要求に対応
- 備考
  - AWS上で構築する場合はGlue Data CatalogとS3の組み合わせ、またはS3 Tablesで実現
  - 本格的なETL処理にはApache Sparkの知識が必要

#### S3 Tables

- 用途: S3上でIcebergテーブルを管理するためのAWSのマネージドサービス
- 強み
  - Icebergテーブルの管理をAWSがフルマネージドで提供
    - セルフマネージで作るよりもIcebergの知識が少なくて済む
  - S3上でIcebergテーブルを簡単に作成・管理できるため、運用負荷が低い
  - Glue Data Catalogとの統合により、データカタログの管理も容易
  - LakeFormation等の支援も受けられる
- 懸念点
　- Apache Icebergの最新機能をすぐに使えるわけではない
　- ただS3を使うよりコストがかかる
　- Icebergの知識がある程度は必要
- 備考
　- AWSはIcebergをOpen Table Formatの中でも特に推奨しているため、将来的なサポートや機能追加が期待できる
　- とりあえずやってみるクラスで有ればS3上にIcebergを構築するよりもS3 Tablesを使うのが良い

### データクエリ

#### Athena

- 用途: クエリエディタ
- 強み
  - コンソールから容易に操作可能
  - SQLベースでのデータ抽出・分析ができる
  - 多様なシステムと連携可能
  - Icebergテーブルの読み取りに対応
  - AWS内のシステムとの親和性が高い
- 懸念点
  - AWS外のデータ取得・参照は不可
  - SnowflakeやRedshift等の外部DWHは直接参照できない
    - その必要性は薄い
- 備考
　- 料金体系はスキャン量比例なため、データ構造の設計が重要
  　- Icebergテーブルを使用することで、スキャン量を抑えることが可能

### 権限管理

#### Amazon LakeFormation

- 用途: データへのアクセス権限設定
- 強み
  - データレイクやDWH部分のきめ細かなアクセス制御が可能。カラムレベルの権限制御や監査証跡の確保など、セキュリティ要求を満たす
  - AWSアカウント間の権限指定などのシステムも構築可能
  - マネージドサービスであるため、運用負荷が低い
  - データカタログとの統合により、データのメタデータ管理も容易
  - データレイクの権限管理を一元化できるため、運用の効率化が図れる
- 懸念点
  - データレイクが大規模化した際、権限管理ルールの策定が必要
  - AWSサービスに依存するため、クラウドベンダーロックインのリスクがある

### Data Warehouse

#### Snowflake

- 用途: DWHとして全体を統括する形での導入
- 強み
  - 事業者ごとにアカウントを分割し、データを個々の事業者アカウント内に留めることができる
    - 指定した事業者同士や統括アカウントからのアクセスも可能
    - データメッシュの考え方に近い
  - AI関連サービスも提供
  - サポート体制が充実
  - MarketPlaceを利用することで、外部データソースとの連携が容易
  - 従量課金のため、スモールスタート時のコスト負担が小さい
    - データレイクを直接参照することでストレージコストを抑えられるが、コンピューティングコストが主となるため影響は限定的
- 懸念点
  - 機能が多く、要件によっては過剰な場合もある
  - クラウドベンダーロックインは回避できるが、Snowflake自体へのロックインリスクあり
- 備考
  - Snowflake様々なクラウドサービス上でホスティングできる
  - AI等のサービスを利用すると別途コストが発生する
  - Snowflakeの機能をフルに活用するには、ある程度の学習コストが必要

### 要検討課題

- 本格的な分析を行う際には、目的に応じた様々なシステムの導入が必要となる
- 可視化やBIツールについては別途検討が必要
- コネクタが存在しないデータソースを利用する場合は、別途ETLツールの検討が必要
  - 事業者固有のデータなど
- 個人情報を扱う範囲を明確にし、適切なマスキングや情報量の削減等を検討する必要がある
  - 一番楽なのはUserIdをハッシュ化し、その他のPIIを削除すること
